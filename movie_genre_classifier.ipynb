{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: add pip install command for all dependencies\n",
    "# install dependencies\n",
    "#!conda install -c conda-forge scikit-learn lightgbm langcodes prince xgboost imblearn scikit-multilearn transformers pytorch -y"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import dependencies\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "import langcodes\n",
    "from prince import MCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "id": "1f377dd7d5387860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_json_path = 'data/movie_data.json'\n",
    "data_csv_path = 'data/movie_data.csv'\n",
    "if not os.path.exists(data_csv_path):\n",
    "    with open(data_json_path, 'r') as f:\n",
    "        data = list(map(json.loads, f.readlines()))\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(data_csv_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(data_csv_path)"
   ],
   "id": "1b409d10e981250c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data Exploratoin",
   "id": "f81886b1d7b99701"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print columns types, shape, missing values ratio, value counts\n",
    "print(df.info())\n",
    "print(f'{df.shape=}')\n",
    "missing_values_ratio = (df.isnull().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "print(f'missing values ratio: {print(missing_values_ratio)}')"
   ],
   "id": "a0bb15d894dde3cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check for rows that have missing values across all features\n",
    "print(df.isnull().all(axis=0).sum())"
   ],
   "id": "252aa1f3b29b58ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(df.head())",
   "id": "27b2e0ee235a54d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# remove irrelevant attributes\n",
    "# release date doesn't seem to add any useful information for predicting genres\n",
    "df.drop('release_date', axis=1, inplace=True)"
   ],
   "id": "885da6b43d833a37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "### There aren't any rows with missing values across all features",
   "id": "fe4f963c5e0092b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('unique values:')\n",
    "str_cols = df.select_dtypes(include='object').columns\n",
    "for col in str_cols:\n",
    "    # print number of unique values\n",
    "    print(f'{col}: {df[col].nunique()}')"
   ],
   "id": "b910de0541f49a84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_rows = df.shape[0]\n",
    "df.dropna(subset=['genres'], how='any', inplace=True)\n",
    "print(f'dropped {n_rows - df.shape[0]} rows')"
   ],
   "id": "1a2d9705c415cffb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multilabel Encoding",
   "id": "5d5b2097248e0206"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# parse json columns & extract categorical attributes\n",
    "# even though the keys aren't human readable, the values are\n",
    "# we'll convert the dicts to lists of values\n",
    "\n",
    "def parse_json_col(str_):\n",
    "    return list(eval(str_).values())\n",
    "\n",
    "json_cols = ['languages', 'genres', 'countries']\n",
    "# df_raw[json_cols].fillna('{}', inplace=True)\n",
    "for col in json_cols:\n",
    "    # treat missing values as empty dict\n",
    "    df[col] = df[col].fillna('{}')\n",
    "    df[f'{col}_parsed'] = df[col].astype(str).apply(parse_json_col)\n",
    "    # drop col\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "parsed_json_cols = [f'{col}_parsed' for col in json_cols]\n",
    "print(df[parsed_json_cols].head())"
   ],
   "id": "f9fa05ff3b64cd29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# drop all rows where y is empty list\n",
    "n_rows = df.shape[0]\n",
    "df = df[df.genres_parsed.apply(len) > 0]\n",
    "print(f'dropped {n_rows - df.shape[0]} rows')"
   ],
   "id": "5c91a2f7cc7a96c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print unique values in each of the parsed json columns\n",
    "for col in parsed_json_cols:\n",
    "    print('-' * 100)\n",
    "    print(f'{col}:')\n",
    "    print(sorted(set(itertools.chain.from_iterable(df[col].values))))"
   ],
   "id": "8dff2a3f2b52129a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some values in languages_parsed need to be merged like \"German\" and \"German Language\"\n",
    "\n",
    "We'll use langcodes to convert natural language names to language codes\n",
    "\n",
    "Note: this isn't a perfect solution, langcodes fails to identify some of the languages included in the dataset,  we'll handle them as missing data"
   ],
   "id": "657f0f1c6b25d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# convert to language codes\n",
    "languages_unique_values = set(itertools.chain.from_iterable(df.languages_parsed.values))\n",
    "langcode_map = {}\n",
    "for v in languages_unique_values:\n",
    "    try:\n",
    "        langcode_map[v] = langcodes.find(v)\n",
    "    except LookupError:\n",
    "        langcode_map[v] = ''\n",
    "\n",
    "df['langcodes'] = df['languages_parsed'].apply(\n",
    "    lambda x: [(langcode_map[v].language if isinstance(langcode_map[v], langcodes.Language) else langcode_map[v]) for v in x])\n",
    "# drop languages_parsed\n",
    "df.drop('languages_parsed', axis=1, inplace=True)"
   ],
   "id": "3669d76ff721031"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Some values in countries column include languages\n",
    "# remove\" Language\" from countries_parsed values\n",
    "df['countries_parsed'] = df['countries_parsed'].apply(lambda x: [v.replace(' Language', '') for v in x])"
   ],
   "id": "be2abb26299305eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cat_multi_cols_X = ['langcodes', 'countries_parsed']\n",
    "cat_multi_cols_y = ['genres_parsed']\n",
    "cat_multi_cols = cat_multi_cols_X + cat_multi_cols_y\n",
    "for col in cat_multi_cols:\n",
    "    print(f'{col} unique values: {len(set(itertools.chain.from_iterable(df[col].values)))}')"
   ],
   "id": "e5efcf93e8909ea7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using one hot encoding will add additional 296 attributes to the dataset, we can use MCA to encode these attributes at a lower dimensionality\n",
    "We'll start with one hot encoding and use MCA to reduce the dimensionality"
   ],
   "id": "557cdf5a86d5e96e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "df_bak = df.copy()\n",
    "# df = df_bak.copy()\n",
    "n_features = df.shape[1]\n",
    "one_hot_cols_X = []\n",
    "for col in cat_multi_cols:\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    encoded_col = mlb.fit_transform(df[col])\n",
    "    encoded_df = pd.DataFrame(encoded_col, columns=[f'{col}_{v}' for v in mlb.classes_], index=df.index)\n",
    "    if col in cat_multi_cols_X:\n",
    "        one_hot_cols_X.extend(encoded_df.columns)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print(f'{df.shape=}, {df.shape[1] - n_features} new features added')"
   ],
   "id": "7eaff033d17b9cfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# find best number of components for MCA\n",
    "n_components_ratio_candidates = (.5, .7, .8, .9)\n",
    "n_components_candidates = [int(len(one_hot_cols_X)*ratio) for ratio in n_components_ratio_candidates]\n",
    "cumulative_eigenvalues = []\n",
    "for n_components in tqdm(n_components_candidates, desc='fitting MCA'):\n",
    "    mca = MCA(n_components=n_components)\n",
    "    mca.fit(df[one_hot_cols_X])\n",
    "    cumulative_eigenvalues.append(mca.eigenvalues_.sum())\n",
    "# plot cumulative eigenvalues\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(n_components_ratio_candidates, cumulative_eigenvalues)\n",
    "plt.xlabel('n_components_ratio_candidates')\n",
    "plt.ylabel('cumulative_eigenvalues')\n",
    "plt.show()"
   ],
   "id": "748a2b2f75ac53f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# int(len(one_hot_cols)*.8) gives .95 of the explained variance\n",
    "n_components = int(len(one_hot_cols_X)*.8)\n",
    "mca = MCA(n_components=n_components)\n",
    "mca_df = mca.fit_transform(df[one_hot_cols_X])\n",
    "mca_df.columns = [f'mca_{i}' for i in range(n_components)]\n",
    "# replace one hot encoded columns with MCA columns\n",
    "df = pd.concat([df, mca_df], axis=1)\n",
    "df.drop(one_hot_cols_X, axis=1, inplace=True)"
   ],
   "id": "f7e1e4f3d21502d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# handle numerical columns\n",
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "print((df[numerical_cols].isnull().sum() / df[numerical_cols].shape[0]))\n",
    "print(df[numerical_cols].describe())"
   ],
   "id": "f05d6d6b7ae01170"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### 82% of rows are missing movie_box_office_revenue, we'll drop this column\n",
    "df.drop('movie_box_office_revenue', axis=1, inplace=True)\n",
    "# fill feature_length missing values with the median value\n",
    "df['feature_length'].fillna(df['feature_length'].median(), inplace=True)"
   ],
   "id": "81ffe5dd8ad9142b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "title and plot_summary attributes are unique per row, therefore it makes more sense to treat them as text features to give them semantic meaning, rather than one-hot encoding them",
   "id": "beac0d0a7b146430"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embedding_size = model.config.hidden_size\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def get_embeddings(texts: List[str], batch_size: int):\n",
    "    all_embeddings = []\n",
    "    print(f\"Total number of records: {len(texts)}\")\n",
    "    print(f\"Num batches: {(len(texts) // batch_size) + 1}\")\n",
    "\n",
    "    # Extract embeddings for the texts in batches\n",
    "    for start_index in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[start_index:start_index + batch_size]\n",
    "\n",
    "        # Generate tokens and move input tensors to GPU\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        # Extract the embeddings. no_grad because the gradient does not need to be computed\n",
    "        # since this is not a learning task\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Get the last hidden stated and pool them into a mean vector calculated across the sequence length dimension\n",
    "        # This will reduce the output vector from [batch_size, sequence_length, hidden_layer_size]\n",
    "        # to [batch_size, hidden_layer_size] thereby generating the embeddings for all the sequences in the batch\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = torch.mean(last_hidden_states, dim=1).cpu().tolist()\n",
    "\n",
    "        # Append to the embeddings list\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    return all_embeddings"
   ],
   "id": "c892089613161d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace missing values with empty strings\n",
    "df['title'].fillna('', inplace=True)\n",
    "df['plot_summary'].fillna('', inplace=True)"
   ],
   "id": "c71b5439278f62d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# convert title and plot_summary into text embeddings\n",
    "df['title_embeddings'] = get_embeddings(df['title'].values.tolist(), batch_size=128)\n",
    "df['plot_summary_embeddings'] = get_embeddings(df['plot_summary'].values.tolist(), batch_size=128)\n",
    "# create attributes to match embeddings size\n",
    "for i in range(embedding_size):\n",
    "    df[f'title_embedding_{i}'] = df['title_embeddings'].apply(lambda x: x[i])\n",
    "    df[f'plot_summary_embedding_{i}'] = df['plot_summary_embeddings'].apply(lambda x: x[i])\n",
    "# drop title and plot_summary\n",
    "df.drop(['title', 'plot_summary', 'title_embeddings', 'plot_summary_embeddings'], axis=1, inplace=True)"
   ],
   "id": "b78caf3499fffc6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(df.info())\n",
    "for col in df.columns:\n",
    "    print(f'{col}: {df[col].dtype}')\n",
    "print({df[c].dtype for c in df.columns})"
   ],
   "id": "e773056084946d63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save the processed data\n",
    "df.to_csv('data/movie_data_processed.csv', index=False)"
   ],
   "id": "62de1e06c655203b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # load the processed data\n",
    "# df = pd.read_csv('data/movie_data_processed.csv')"
   ],
   "id": "e850d1d14a9b222f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# split dataset\n",
    "df_shuffled = df.sample(frac=1, random_state=SEED)\n",
    "y_cols = df_shuffled.columns[df_shuffled.columns.str.startswith('genres_parsed_')]\n",
    "X = df_shuffled.drop(y_cols, axis=1).values\n",
    "y = df_shuffled[y_cols].values\n",
    "print(f'{X.shape=}, {y.shape=}')\n",
    "# we'll use train_test_split default 0.25 test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=.25,\n",
    "                                                    # stratify=y,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=SEED)\n",
    "\n",
    "print(f'{X_train.shape=}, {y_train.shape=} {X_test.shape=}, {y_test.shape=}')"
   ],
   "id": "74c244cfbf6f3792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Data standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# X_train_rus, y_train_rus = RandomUnderSampler(random_state=SEED).fit_resample(X_train, y_train)\n",
    "# print(pd.Series(y_train_rus).value_counts())"
   ],
   "id": "b8d8cf9332ebe8fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data balancing\n",
    "Since we're dealing with multilabel classification,\n",
    "Well need to encode y into 1D array before applying RandomUnderSampler.\n",
    "I chose to go with under sampling rather than over sampling."
   ],
   "id": "f8f784e9c46ae8db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lp = LabelPowerset()\n",
    "rus = RandomUnderSampler(random_state=SEED)\n",
    "# ros = RandomOverSampler(random_state=SEED)\n",
    "\n",
    "# Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n",
    "yt = lp.transform(y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, yt)\n",
    "# Inverts the ML-MC transformation to recreate the ML set\n",
    "y_resampled = lp.inverse_transform(y_resampled).toarray()"
   ],
   "id": "78f93415eb5844f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# build model evaluation function\n",
    "def val_model(X, y, clf, scoring, **cross_val_args):\n",
    "    \"\"\"\n",
    "    Performs cross-validation with training data for a given model.\n",
    "\n",
    "    # Arguments\n",
    "        X: Data Frame, contains the independent variables.\n",
    "        y: Series, vector containing the target variable.\n",
    "        clf:scikit-learn classifier model.\n",
    "        quite: bool, indicating whether the function should print the results or not.\n",
    "\n",
    "    # Returns\n",
    "        float, average of cross-validation scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert variables to arrays\n",
    "    t_start = time.time()\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # create pipeline\n",
    "    ## 1. standardize data with StandardScaler\n",
    "    ## 2. classify the data\n",
    "    pipeline = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # model evaluation by cross-validation\n",
    "    ## according to the Recall value\n",
    "    scores = cross_val_score(pipeline, X, y, n_jobs=-1, scoring=scoring, **cross_val_args)\n",
    "\n",
    "    run_time_str = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - t_start))\n",
    "    print(f\"{scoring}: {scores.mean():.4f} (+/- {scores.std():.2f}), Time: {run_time_str}\")\n",
    "    # return the average of the Recall values obtained in cross-validation\n",
    "    return scores.mean()"
   ],
   "id": "da8d15f36505b292"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# instantiate base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# evaluate model performance with the 'val_model' function\n",
    "micro_baseline = val_model(X_resampled, y_resampled, rf, scoring='recall_micro', cv=3)"
   ],
   "id": "447d40034431b3f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Compare models\n",
    "# instantiate the models\n",
    "rf   = RandomForestClassifier()\n",
    "knn  = KNeighborsClassifier()\n",
    "dt   = DecisionTreeClassifier()\n",
    "# models that don't support multilabel classification can be wrapped in OneVsRestClassifier\n",
    "sgdc = OneVsRestClassifier(SGDClassifier())\n",
    "svc  = OneVsRestClassifier(LinearSVC(multi_class='ovr'))\n",
    "lr   = OneVsRestClassifier(LogisticRegression())\n",
    "xgb  = XGBClassifier(objective='binary:logistic')\n",
    "multi_xgb = MultiOutputClassifier(XGBClassifier(objective='binary:logistic'))\n",
    "lgbm = OneVsRestClassifier(LGBMClassifier())\n",
    "classifiers = [rf, knn, dt, sgdc, svc, lr, xgb, multi_xgb, lgbm]\n",
    "# classifiers = [sgdc, svc, lr, xgb, lgbm, rf, knn]\n",
    "# create lists to store:\n",
    "## the classifier model\n",
    "# model = []\n",
    "## the value of the Recall\n",
    "recall_results = {}\n",
    "\n",
    "# for practical reasons, we'll train on a subset of the data to reduce training time\n",
    "n_samples = 6000\n",
    "X_train_reduced, y_train_reduced = X_resampled[:n_samples], y_resampled[:n_samples]\n",
    "\n",
    "# create loop to cycle through classification models\n",
    "for clf in tqdm(classifiers[:2]):\n",
    "    # apply 'val_model' function and store the obtained Recall value\n",
    "    clf_recall = val_model(X_train_reduced, y_train_reduced, clf, scoring='recall_micro')\n",
    "    recall_results[repr(clf)] = clf_recall\n",
    "\n",
    "# save the Recall result obtained in each classification model in a variable\n",
    "results = pd.DataFrame(data=recall_results.values(), index=recall_results.keys(), columns=['Recall'])\n",
    "\n",
    "# show the models based on the Recall value obtained, from highest to lowest\n",
    "print(results.sort_values(by='Recall', ascending=False))"
   ],
   "id": "6c0aa9f8a302c3e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def xgb_hyperparam_search(X, y, param_grid, **xgb_args):\n",
    "    # set the learning rate to 0.1 and set the seed\n",
    "    xgb = XGBClassifier(**xgb_args)\n",
    "    # set up cross validation with 5 stratified folds\n",
    "    # shuffle=True to shuffle the data before splitting and setting the seed\n",
    "    kfold = StratifiedKFold(shuffle=True, random_state=SEED)\n",
    "    # configuring the search for cross matches with the XGBoost classifier\n",
    "    grid_search = GridSearchCV(xgb, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    return grid_result.best_score_, grid_result.best_params_\n"
   ],
   "id": "52f43d5621c57d8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# search n_estimators\n",
    "params_grid = {'n_estimators':range(0,500,50)}\n",
    "xgb_args = {'learning_rate':0.1, 'random_state':SEED}\n",
    "best_score, best_params = xgb_hyperparam_search(X_train_reduced, y_train_reduced, params_grid, **xgb_args)\n",
    "print(f'best params: {best_score=:.4f}, {best_params=:.4f}')"
   ],
   "id": "dfe2b464d4a6e3f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract the best n_estimators from the previous search\n",
    "best_n_estimators = best_params['n_estimators']\n",
    "# Refine search for n_estimators with a narrower range around the best value found\n",
    "narrow_range_start = max(0, best_n_estimators - 25)\n",
    "narrow_range_end = best_n_estimators + 25\n",
    "params_grid = {'n_estimators': range(narrow_range_start, narrow_range_end, 5)}\n",
    "best_score, best_params = xgb_hyperparam_search(X_train_reduced, y_train_reduced, params_grid, **xgb_args)\n",
    "print(f'Refined best params: {best_score=:.4f}, {best_params}')"
   ],
   "id": "3e8850fef92dc259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Search for max_depth and min_child_weight\n",
    "params_grid = {'max_depth': range(1, 8, 1),\n",
    "               'min_child_weight': range(1, 5, 1)}\n",
    "best_score, best_params = xgb_hyperparam_search(X_train_reduced, y_train_reduced, params_grid, **xgb_args)\n",
    "print(f'Final best params: {best_score=:.4f}, {best_params}')"
   ],
   "id": "485c1b09bf6c2453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# instantiate the model with the best hyperparameters\n",
    "xgb_best = XGBClassifier(learning_rate=0.1, n_estimators=best_n_estimators, max_depth=best_params['max_depth'],\n",
    "                         min_child_weight=best_params['min_child_weight'], random_state=SEED)\n",
    "xgb_best.fit(X_train, y_train)"
   ],
   "id": "a90d4f18825c1094"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# standardize test data\n",
    "X_test = scaler.transform(X_test)\n",
    "# make predictions with test data\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ],
   "id": "52930291a39cd67b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
